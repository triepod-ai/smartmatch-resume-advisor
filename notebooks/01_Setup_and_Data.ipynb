{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ SmartMatch Resume Analyzer - Part 1: Setup and Data\n",
    "\n",
    "> **Interactive tutorial demonstrating setup, dependencies, and data models for AI-powered resume optimization**\n",
    "\n",
    "This is the first notebook in a 3-part series exploring the SmartMatch Resume Analyzer's AI pipeline. In this notebook, you'll learn how to set up the environment and understand the data models that power the analysis.\n",
    "\n",
    "## üìö Tutorial Series Overview\n",
    "\n",
    "1. **Part 1: Setup and Data** (This notebook) - Environment setup, dependencies, and data models\n",
    "2. **Part 2: Analysis Pipeline** - Core AI analysis engine and LangChain integration  \n",
    "3. **Part 3: Results and Interpretation** - Running analyses and understanding results\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "- **Environment Setup**: Configure OpenAI API and required dependencies\n",
    "- **Data Models**: Understand Pydantic models for type safety\n",
    "- **Sample Data**: Work with realistic resume and job description examples\n",
    "- **Production Patterns**: See how to structure NLP applications for reliability\n",
    "\n",
    "## üöÄ Technical Stack\n",
    "\n",
    "- **LangChain**: Document processing and LLM chain orchestration\n",
    "- **OpenAI GPT-3.5-turbo**: Semantic analysis and text generation\n",
    "- **Pydantic**: Type safety and automatic response validation\n",
    "- **Python 3.11+**: Modern Python with async/await patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Dependencies\n",
    "\n",
    "First, let's install the required dependencies. This notebook demonstrates the same pipeline used in the production application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install langchain>=0.3.0 langchain-openai>=0.3.0 langchain-community>=0.3.0 \n",
    "!pip install openai>=1.0.0 pydantic>=2.5.3 python-dotenv>=1.0.0\n",
    "!pip install asyncio nest-asyncio  # For Jupyter notebook async support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Pydantic for data validation\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "# Enable async in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"‚úÖ Dependencies loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Environment Configuration\n",
    "\n",
    "Configure your OpenAI API key. For production use, always use environment variables or secure configuration management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key\n",
    "# Option 1: From environment variable (recommended)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Option 2: Direct input (for tutorial only - not recommended for production)\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Verify API key is configured\n",
    "if OPENAI_API_KEY and len(OPENAI_API_KEY) > 20:\n",
    "    print(f\"‚úÖ API key configured (length: {len(OPENAI_API_KEY)})\")\n",
    "else:\n",
    "    print(\"‚ùå Please configure your OpenAI API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Data Models\n",
    "\n",
    "Define Pydantic models for type safety and automatic validation - a crucial pattern for production NLP applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BulletSuggestion(BaseModel):\n",
    "    \"\"\"Model for bullet point improvement suggestions.\"\"\"\n",
    "    original: str = Field(..., description=\"Original bullet point\")\n",
    "    improved: str = Field(..., description=\"AI-improved version\")\n",
    "    reason: str = Field(..., description=\"Explanation of improvements\")\n",
    "\n",
    "class AnalysisResponse(BaseModel):\n",
    "    \"\"\"Complete analysis response model with validation.\"\"\"\n",
    "    match_percentage: float = Field(..., ge=0, le=100, description=\"Match percentage\")\n",
    "    matched_keywords: List[str] = Field(default=[], description=\"Keywords found in both texts\")\n",
    "    missing_keywords: List[str] = Field(default=[], description=\"Job keywords missing from resume\")\n",
    "    suggestions: List[BulletSuggestion] = Field(default=[], description=\"Improvement suggestions\")\n",
    "    strengths: List[str] = Field(default=[], description=\"Resume strengths\")\n",
    "    areas_for_improvement: List[str] = Field(default=[], description=\"Areas needing improvement\")\n",
    "    overall_feedback: str = Field(..., description=\"Summary feedback\")\n",
    "    processing_time: Optional[float] = Field(None, description=\"Analysis processing time\")\n",
    "\n",
    "print(\"‚úÖ Data models defined with Pydantic validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Sample Data\n",
    "\n",
    "Let's prepare realistic sample data to demonstrate the AI analysis capabilities in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample resume - Software Engineer transitioning to ML\n",
    "SAMPLE_RESUME = \"\"\"\n",
    "John Smith\n",
    "Software Engineer\n",
    "Email: john.smith@email.com\n",
    "\n",
    "PROFESSIONAL SUMMARY\n",
    "Experienced software engineer with 5+ years developing scalable web applications and data pipelines.\n",
    "Strong background in Python, cloud technologies, and agile development practices.\n",
    "\n",
    "TECHNICAL SKILLS\n",
    "Languages: Python, JavaScript, SQL, Java\n",
    "Frameworks: Django, Flask, React, Node.js\n",
    "Databases: PostgreSQL, MongoDB, Redis\n",
    "Cloud: AWS (EC2, S3, Lambda), Docker, Kubernetes\n",
    "Tools: Git, Jenkins, JIRA, Prometheus\n",
    "\n",
    "EXPERIENCE\n",
    "Senior Software Engineer | TechCorp | 2021-2024\n",
    "‚Ä¢ Developed real-time data processing pipeline using Apache Kafka handling 100k+ messages/hour\n",
    "‚Ä¢ Optimized database queries improving response time by 40% through indexing and query optimization\n",
    "‚Ä¢ Led team of 3 engineers in implementing microservices architecture using Docker and Kubernetes\n",
    "‚Ä¢ Mentored junior developers and conducted code reviews maintaining 95% code quality standards\n",
    "\n",
    "Software Engineer | StartupXYZ | 2019-2021\n",
    "‚Ä¢ Built REST APIs using Django and Flask serving 10,000+ daily active users\n",
    "‚Ä¢ Implemented automated testing and CI/CD pipelines reducing deployment time by 60%\n",
    "‚Ä¢ Collaborated with product team using agile methodologies and sprint planning\n",
    "\n",
    "EDUCATION\n",
    "Bachelor of Science in Computer Science | University of Technology | 2019\n",
    "\"\"\"\n",
    "\n",
    "# Sample job description - Machine Learning Engineer\n",
    "SAMPLE_JOB_DESCRIPTION = \"\"\"\n",
    "Machine Learning Engineer\n",
    "Company: AI Innovations Inc.\n",
    "\n",
    "We are seeking a skilled Machine Learning Engineer to join our AI team and help build next-generation ML solutions.\n",
    "\n",
    "REQUIREMENTS:\n",
    "‚Ä¢ 3+ years of experience in machine learning and data science\n",
    "‚Ä¢ Strong proficiency in Python and machine learning frameworks (TensorFlow, PyTorch, Scikit-learn)\n",
    "‚Ä¢ Experience with MLOps practices, model deployment, and monitoring\n",
    "‚Ä¢ Knowledge of deep learning, neural networks, and NLP techniques\n",
    "‚Ä¢ Experience with cloud platforms (AWS, GCP) and containerization (Docker)\n",
    "‚Ä¢ Strong background in statistics, mathematics, and data analysis\n",
    "‚Ä¢ Experience with model training, evaluation, and optimization\n",
    "\n",
    "RESPONSIBILITIES:\n",
    "‚Ä¢ Design and implement machine learning models for various business problems\n",
    "‚Ä¢ Build and maintain ML pipelines from data ingestion to model deployment\n",
    "‚Ä¢ Collaborate with data scientists and engineers to productionize ML solutions\n",
    "‚Ä¢ Monitor model performance and implement improvements\n",
    "‚Ä¢ Research and evaluate new ML techniques and technologies\n",
    "\n",
    "PREFERRED QUALIFICATIONS:\n",
    "‚Ä¢ MS/PhD in Computer Science, Machine Learning, or related field\n",
    "‚Ä¢ Experience with distributed computing and big data technologies\n",
    "‚Ä¢ Publications in ML conferences or journals\n",
    "‚Ä¢ Experience with recommendation systems, computer vision, or NLP\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìÑ Sample data loaded:\")\n",
    "print(f\"   Resume: {len(SAMPLE_RESUME)} characters\")\n",
    "print(f\"   Job Description: {len(SAMPLE_JOB_DESCRIPTION)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Setup Complete!\n",
    "\n",
    "Perfect! You've successfully:\n",
    "\n",
    "- ‚úÖ **Installed Dependencies**: All required packages for NLP analysis\n",
    "- ‚úÖ **Configured API Access**: OpenAI API key ready for use\n",
    "- ‚úÖ **Defined Data Models**: Type-safe Pydantic models for validation\n",
    "- ‚úÖ **Loaded Sample Data**: Realistic resume and job description examples\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Continue to **Part 2: Analysis Pipeline** to build the core AI analysis engine and see how LangChain and OpenAI work together to provide intelligent resume optimization.\n",
    "\n",
    "---\n",
    "\n",
    "*Part of the SmartMatch Resume Analyzer tutorial series. Built with ‚ù§Ô∏è using LangChain, OpenAI, and modern Python.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}