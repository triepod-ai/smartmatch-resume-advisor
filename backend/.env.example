# =============================================================================
# SmartMatch Resume Analyzer - Environment Configuration
# =============================================================================
# Copy this file to .env and configure the values below

# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================

# OpenAI API Configuration (REQUIRED)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# API SERVER CONFIGURATION
# =============================================================================

# API server host and port
API_HOST=0.0.0.0
API_PORT=8000

# Frontend URL for CORS (adjust if running on different port)
FRONTEND_URL=http://localhost:3000

# Environment (development, production)
ENVIRONMENT=development

# Enable debug logging (true/false)
DEBUG=false

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================

# OpenAI model for analysis (gpt-3.5-turbo recommended for speed/cost)
MODEL_NAME=gpt-3.5-turbo

# Model parameters
MAX_TOKENS=2000
TEMPERATURE=0.1

# Embedding model for semantic analysis (optional, only if using vector search)
EMBEDDING_MODEL=text-embedding-ada-002

# =============================================================================
# LANGCHAIN CONFIGURATION (OPTIONAL)
# =============================================================================

# LangSmith tracing (optional, for debugging LLM chains)
# Get your key from: https://smith.langchain.com/
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your_langsmith_key_here
LANGCHAIN_PROJECT=resume-analyzer

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000

# API key header for authentication
API_KEY_HEADER=X-API-Key

# Rate limiting (requests per minute)
RATE_LIMIT_REQUESTS=100

# Maximum request size in bytes
MAX_REQUEST_SIZE=1048576

# =============================================================================
# ANALYSIS CONFIGURATION
# =============================================================================

# Minimum keyword match threshold (0.0-1.0)
MIN_MATCH_THRESHOLD=0.3

# Maximum number of suggestions to generate
MAX_SUGGESTIONS=5

# Text processing chunk size
CHUNK_SIZE=1000

# Overlap between text chunks
CHUNK_OVERLAP=200

# Maximum keywords to extract
MAX_KEYWORDS=50

# Analysis timeout in seconds
ANALYSIS_TIMEOUT=60

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================

# Request timeout in seconds
REQUEST_TIMEOUT=30

# Maximum number of API retries
MAX_RETRIES=3

# Max concurrent async operations
ASYNC_CONCURRENCY=10

# Cache TTL in seconds (0 to disable)
CACHE_TTL=3600

# Enable response caching (true/false)
ENABLE_CACHING=true

# Enable response compression (true/false)
RESPONSE_COMPRESSION=true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log format string
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Log file rotation size in bytes
LOG_MAX_SIZE=10485760

# Number of log file backups to keep
LOG_BACKUP_COUNT=5

# Enable HTTP access logging (true/false)
ENABLE_ACCESS_LOGGING=true

# =============================================================================
# DATABASE/STORAGE CONFIGURATION (OPTIONAL)
# =============================================================================

# Database connection URL (optional)
DATABASE_URL=

# Redis connection URL (optional)
REDIS_URL=redis://localhost:6379/0

# Storage backend (local, s3, gcs, azure)
STORAGE_BACKEND=local

# Directory for file uploads
UPLOAD_DIRECTORY=uploads

# =============================================================================
# MONITORING CONFIGURATION
# =============================================================================

# Enable Prometheus metrics (true/false)
ENABLE_METRICS=true

# Port for metrics endpoint
METRICS_PORT=8001

# Health check interval in seconds
HEALTH_CHECK_INTERVAL=30

# Enable performance monitoring (true/false)
PERFORMANCE_MONITORING=true

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable experimental features (true/false)
ENABLE_EXPERIMENTAL_FEATURES=false

# Enable fallback analysis when LLM fails (true/false)
ENABLE_FALLBACK_ANALYSIS=true

# Enable semantic similarity search (true/false)
ENABLE_SEMANTIC_SEARCH=true

# Enable batch processing (true/false)
ENABLE_BATCH_PROCESSING=false

# =============================================================================
# BUSINESS LOGIC CONFIGURATION
# =============================================================================

# Supported languages (comma-separated)
SUPPORTED_LANGUAGES=en

# Supported file types (comma-separated)
SUPPORTED_FILE_TYPES=txt,pdf,docx

# Maximum file upload size in bytes
MAX_FILE_SIZE=5242880

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================
# 1. Copy this file: cp .env.example .env
# 2. Get your OpenAI API key from: https://platform.openai.com/api-keys
# 3. Replace 'your_openai_api_key_here' with your actual API key
# 4. Optionally configure other settings above
# 5. Run: npm run dev
